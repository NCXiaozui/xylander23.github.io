<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="John Doe"><title>Spark简易笔记 · 理想與少年</title><!-- hexo-inject:begin --><!-- hexo-inject:end --><meta name="description" content="Spark简介：  Spark主要核心的组件包含:Spark SQL、Spark Streaming、MLLib、GraphX和Apache Spark Core Engine。  
  这里，我主要介绍如何使用PySpark这个接口去使用Spark,具体的Spark的理论，我也还没完成理清楚，等我"><meta name="keywords" content="CS"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/style.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div id="stage" class="container"><div class="row"><div id="side-bar" class="col-sm-3 col-xs-12 side-container invisible"><div class="vertical-text site-title"><h3 tabindex="-1" class="site-title-small"><a href="/" class="a-title">與數學和零壹斗智斗勇的理想少年</a></h3><h1 tabindex="-1" class="site-title-large"><a href="/" class="a-title">江右少年</a></h1><!--h6(onclick="triggerSiteNav()") Trigger--></div><br class="visible-lg visible-md visible-sm"><div id="site-nav" class="site-title-links"><ul><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/categories">分类</a></li><li><a href="/tags">标签</a></li><li class="soc"><a href="https://github.com/xylander23" target="_blank" rel="noopener noreferrer"><i class="fa fa-github">&nbsp;</i></a></li></ul><div class="visible-lg visible-md visible-sm site-nav-footer"><br class="site-nav-footer-br"><footer><p>&copy;&nbsp;2019&nbsp;<a target="_blank" href="http://yoursite.com" rel="noopener noreferrer">John Doe</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div><div id="main-container" class="col-sm-9 col-xs-12 main-container invisible"><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post-container"><p class="post-title"><a>Spark简易笔记</a></p><p class="post-meta"><span class="date meta-item">发布于&nbsp;2018-03-24</span><span class="meta-item"><i class="fa fa-folder"></i><span>&nbsp;</span><a href="/categories/CS/" title="CS" class="a-tag">CS</a><span>&nbsp;</span></span><span class="meta-item"><i class="fa fa-tag"></i><span>&nbsp;</span><a href="/tags/Spark/" title="Spark" class="a-tag">Spark</a><span>&nbsp;</span></span></p><p class="post-abstract"><h1 id="Spark简介："><a href="#Spark简介：" class="headerlink" title="Spark简介："></a>Spark简介：</h1><p>  Spark主要核心的组件包含:Spark SQL、Spark Streaming、MLLib、GraphX和Apache Spark Core Engine。  </p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><p>  这里，我主要介绍如何使用PySpark这个接口去使用Spark,具体的Spark的理论，我也还没完成理清楚，等我有时间再去整理，然后再写。</p>
<h1 id="Spark核心和弹性分散式资料集（RDDs）"><a href="#Spark核心和弹性分散式资料集（RDDs）" class="headerlink" title="Spark核心和弹性分散式资料集（RDDs）"></a>Spark核心和弹性分散式资料集（RDDs）</h1><p>Spark核心是整个专案的基础，提供了分布式任务调度，和基本的I／O功能，而其基础的程序抽象则称为弹性分布式数据集（RDDs），是一个可以并行操作，有容错机制的数据集合。RDD</p>
<h1 id="PySpark-是-Spark-的-Python-API"><a href="#PySpark-是-Spark-的-Python-API" class="headerlink" title="PySpark 是 Spark 的 Python API"></a>PySpark 是 Spark 的 Python API</h1><h2 id="PySpark的编程思想："><a href="#PySpark的编程思想：" class="headerlink" title="PySpark的编程思想："></a>PySpark的编程思想：</h2><p>  在PySpark编程过程中，时刻记作RDD的形式，要么对应像python的列表，要么就是（key-value）形式的元组。一般元组的操作都可以直接用PySparkContext()里面的操作函数完成，如果是元组形式，那么也可以在函数里面用索引方式调用操作。</p>
<h2 id="公开的类总览："><a href="#公开的类总览：" class="headerlink" title="公开的类总览："></a>公开的类总览：</h2><pre><code>sparkContext：是Spark函数的主要入口点  
RDD：一个弹性分布式数据集，Spark的基本抽象类  
Broadcast:一个可以整个任务重复用的变量  
Accumulator: 一个只可以累加的共享变量  
SparkConf:Spark的基本配置  
SparkFiles：装载工作需要的文件  
StorageLevel: 更细粒度的缓存持久性级别  
TaskContext:关于最近正在运行的任务信息和worker与experimental的情况
</code></pre><p><strong>class pyspark.SparkConf：</strong><br>  一个spark应用的默认设置，用大量Spark参数设置为键值对。<br>  通常情况下，用SparkConf（）创造一个SparkConf对象。<br>  在这里，主要记录SparkConf常用的一个对象：<br>  <strong>setMaster()</strong> 定义联接Master URL。如果你是本机，那么就可以用conf = SparkConf().setMaster(“local[<em>]”)来绑定，其中\</em>表示的是选用本地，尽可能多的使用本地资源。<br>  <strong>setAppName()</strong>  设定你程序的名字</p>
<p><strong>class pyspark.Context:</strong><br>  一个Spark运用的配置。使用大量的键值去设置Spark的参数。<br>  常用对象：<br>  <strong>SparkContext(conf=conf)</strong>初始化流程<br>  <strong>accumulator(value,accum_param)</strong>：value是初始值，AccumulatorParam可以定义如何累加。<br>  <strong>broadcast(value)</strong>：广播一个只读变量供所有其他函数使用，广播变量将只会传给每个cluster一次。</p>
<p>  <strong>parallelize(c,numSlices=Noe)</strong>： 分配一个python的collection到一个RDD的形式。推荐使用xrange如果输入是一个序列生成。</p>
<p>  <strong>range(start,end=None,step=1,numSlices=None)</strong>：创造一个RDD的序列，用法参照python的range。</p>
<p>  <strong>textFile(name,minPartitions=None,use_unicode=True)</strong>：<br>  从HDFS、本地系统或者其他Hadoop-supported文件系统URI读取文件，以及返回RDD的字符型。</p>
<p>  <strong>collect()</strong>：返回一个包括RDD元素的python列表。<strong>注意，除了调试你可能需要看下RDD元素的格式可以用，一般强烈不建议使用这个函数。</strong></p>
<p>  <strong>collectAsMap()</strong>:返回一个在RDD的Key-value元素作为python的字典。</p>
<p>  <strong>countByKey()</strong>:计算每个键值出现的次数，返回一个字典型。</p>
<p>  <strong>filter()</strong>:返回满足条件的RDD</p>
<p>  <strong>map(f)</strong>: 通过一个函数作用于RDD每一个元素上，并返回一个RDD</p>
<p>  <strong>mapValues()</strong>:在不改变值的情况下，转递RDDkey-value的每一个value。</p>
<p>  <strong>reduce(f)</strong>:使用特定的可交换和联想二进制操作，Reduce RDD上面的每一个元素。</p>
<p>  <strong>reduceByKey(func,numPartition=None,partitionFunc=<function portable_hash="">)</function></strong>：在reduce上面增加了一个按键合并过程。</p>
<p>  <strong>saveAsTextFile(path,compressionCodeClas=None)</strong>:通过字符串表示每个元素，保存RDD作为一个文本文件。path为文件路径。</p>
<p>  <strong>coalesce(number)</strong>:这个函数可以让最后的RDD合并成个块，比如是在保存文件时，只输出一个文件的时候，就可以RDD.coalesce(1).saveAsTextFile(“”)</p>
<p>  <strong>repartition()</strong>:随机打乱数据以用来平衡然后进行分区。</p>
<h1 id="提交"><a href="#提交" class="headerlink" title="提交"></a>提交</h1><p>最后你只需要运行spark-submit file.py +参数就可以了。</p>
<p><strong>常用参数有：</strong></p>
<p>–executor-memory 20G</p>
<p>–total executor-cores 100</p>
<h1 id="程序"><a href="#程序" class="headerlink" title="程序"></a>程序</h1><p>这是我写的一个练习的小程序，由于数据是公司的，所以我就不能公布数据。这个主要是统计那么用户的出现国家、省和市的次数，以及列数出现最多的国、省、市。</p>
<p>Code: <a href="https://github.com/xylander23/Spark" target="_blank" rel="noopener">https://github.com/xylander23/Spark</a></p>
</p></div><div class="share"><span>分享到</span>&nbsp;<span class="soc"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></span><span class="soc"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></span><span class="soc"><a href="http://twitter.com/home?status=http://yoursite.com/2018/03/24/Spark简易笔记/%20理想與少年%20Spark简易笔记" class="fa fa-twitter"></a></span></div><div class="pagination"><p class="clearfix"><span class="pre pagbuttons"><a role="navigation" href="/2018/03/24/如何学好数学/" title="如何学好数学"><i class="fa fa-angle-double-left"></i>&nbsp;上一篇: 如何学好数学</a></span><span>&nbsp;</span><span class="next pagbuttons"><a role="navigation" href="/2018/03/24/About-me/" title="About me">下一篇: About me&nbsp;<i class="fa fa-angle-double-right"></i></a></span></p></div><div id="lv-container" data-id="city" data-uid="MTAyMC8zNTE2Mi8xMTY5Nw=="><script type="text/javascript">(function (d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') {
        return;
    }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
})(document, 'script');</script><noscript> Please activate JavaScript for write a comment in LiveRe</noscript></div></div></div></div><div class="visible-xs site-bottom-footer"><footer><p>&copy;&nbsp;2019&nbsp;<a target="_blank" href="http://yoursite.com" rel="noopener noreferrer">John Doe</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div></div><script src="/js/jquery-3.1.0.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/google-analytics.js"></script><script src="/js/typography.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>